{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Ffq6A2-ifzAA"
   },
   "source": [
    "# Интеллектуальный анализ данных – весна 2024\n",
    "# Домашнее задание 6: классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPcxtekTA1Sm"
   },
   "source": [
    "Правила:\n",
    "\n",
    "\n",
    "\n",
    "*   Домашнее задание оценивается в 10 баллов.\n",
    "*   Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
    "*  Можно использовать любые свободные источники с *обязательным* указанием ссылки на них.\n",
    "*  Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
    "*  Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itRtFtrOf0_b"
   },
   "source": [
    "В этом домашнем задании вам предстоит построить классификатор текстов.\n",
    "\n",
    "Будем предсказывать эмоциональную окраску твиттов о коронавирусе.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tNGRVO7_g9mz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import  List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "zOy8iHJQg_Ss",
    "outputId": "01951c93-1976-4fd2-b432-f9ec217dbd17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>9553</td>\n",
       "      <td>54505</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>FYI: Covid-19 Update\\r\\r\\nIf you are a grocery...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23500</th>\n",
       "      <td>32505</td>\n",
       "      <td>77457</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>05-04-2020</td>\n",
       "      <td>Victoria helps with food production for 1st ti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11599</th>\n",
       "      <td>17865</td>\n",
       "      <td>62817</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>21-03-2020</td>\n",
       "      <td>The Supermarkets are loving it - so many despe...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15395</th>\n",
       "      <td>22535</td>\n",
       "      <td>67487</td>\n",
       "      <td>Australia</td>\n",
       "      <td>23-03-2020</td>\n",
       "      <td>@stevebhyve @abcnews yes but have you heard th...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName           Location     TweetAt  \\\n",
       "4738       9553       54505            Georgia  19-03-2020   \n",
       "23500     32505       77457  Vancouver, Canada  05-04-2020   \n",
       "11599     17865       62817     United Kingdom  21-03-2020   \n",
       "15395     22535       67487          Australia  23-03-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "4738   FYI: Covid-19 Update\\r\\r\\nIf you are a grocery...  Extremely Positive  \n",
       "23500  Victoria helps with food production for 1st ti...            Positive  \n",
       "11599  The Supermarkets are loving it - so many despe...            Negative  \n",
       "15395  @stevebhyve @abcnews yes but have you heard th...  Extremely Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('content/tweets_coronavirus.csv', encoding='latin-1')\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2OiDog9ZBlS"
   },
   "source": [
    "Для каждого твитта указано:\n",
    "\n",
    "\n",
    "*   UserName - имя пользователя, заменено на целое число для анонимности\n",
    "*   ScreenName - отображающееся имя пользователя, заменено на целое число для анонимности\n",
    "*   Location - местоположение\n",
    "*   TweetAt - дата создания твитта\n",
    "*   OriginalTweet - текст твитта\n",
    "*   Sentiment - эмоциональная окраска твитта (целевая переменная)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZTMseDkhTC7"
   },
   "source": [
    "## Задание 1 Подготовка (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx2-odn9hdAW"
   },
   "source": [
    "Целевая переменная находится в колонке `Sentiment`.  Преобразуйте ее таким образом, чтобы она стала бинарной: 1 - если у твитта положительная эмоциональная окраска и 0 - если отрицательная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZaQKQ1zEjP15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              11422\n",
       "Negative               9917\n",
       "Extremely Positive     6624\n",
       "Extremely Negative     5481\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts() # узнаём, какие варианты окраски есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃÂT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>As news of the regionÃÂs first confirmed COV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>For corona prevention,we should stop to buy th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3810</td>\n",
       "      <td>48762</td>\n",
       "      <td>Pitt Meadows, BC, Canada</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Due to the Covid-19 situation, we have increas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3811</td>\n",
       "      <td>48763</td>\n",
       "      <td>Horningsea</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>#horningsea is a caring community. LetÃÂs AL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                     Location     TweetAt  \\\n",
       "0      3800       48752                           UK  16-03-2020   \n",
       "1      3801       48753                    Vagabonds  16-03-2020   \n",
       "2      3802       48754                          NaN  16-03-2020   \n",
       "3      3803       48755                          NaN  16-03-2020   \n",
       "4      3804       48756  ÃÂT: 36.319708,-82.363649  16-03-2020   \n",
       "5      3805       48757         35.926541,-78.753267  16-03-2020   \n",
       "6      3807       48759              Atlanta, GA USA  16-03-2020   \n",
       "7      3808       48760             BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "8      3810       48762    Pitt Meadows, BC, Canada   16-03-2020   \n",
       "9      3811       48763                   Horningsea  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet  Sentiment  \n",
       "0  advice Talk to your neighbours family to excha...          1  \n",
       "1  Coronavirus Australia: Woolworths to give elde...          1  \n",
       "2  My food stock is not the only one which is emp...          1  \n",
       "3  Me, ready to go at supermarket during the #COV...          0  \n",
       "4  As news of the regionÃÂs first confirmed COV...          1  \n",
       "5  Cashier at grocery store was sharing his insig...          1  \n",
       "6  Due to COVID-19 our retail store and classroom...          1  \n",
       "7  For corona prevention,we should stop to buy th...          0  \n",
       "8  Due to the Covid-19 situation, we have increas...          1  \n",
       "9  #horningsea is a caring community. LetÃÂs AL...          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"] = df[\"Sentiment\"].apply(lambda x: 1 if x in [\"Positive\", \"Extremely Positive\"] else 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGq1FxJ-kBo5"
   },
   "source": [
    "Сбалансированы ли классы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a7gdNtxckK5V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18046\n",
       "0    15398\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng8BCelMkWb0"
   },
   "source": [
    "**Ответ:** Разница между численностью классов, конечно, есть, но незначительная, поэтому классы сбалансированы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmSIBSsLk5Zz"
   },
   "source": [
    "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их строкой 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UhUVRkR5kxa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃÂT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>As news of the regionÃÂs first confirmed COV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                     Location     TweetAt  \\\n",
       "0      3800       48752                           UK  16-03-2020   \n",
       "1      3801       48753                    Vagabonds  16-03-2020   \n",
       "2      3802       48754                      Unknown  16-03-2020   \n",
       "3      3803       48755                      Unknown  16-03-2020   \n",
       "4      3804       48756  ÃÂT: 36.319708,-82.363649  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet  Sentiment  \n",
       "0  advice Talk to your neighbours family to excha...          1  \n",
       "1  Coronavirus Australia: Woolworths to give elde...          1  \n",
       "2  My food stock is not the only one which is emp...          1  \n",
       "3  Me, ready to go at supermarket during the #COV...          0  \n",
       "4  As news of the regionÃÂs first confirmed COV...          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропуски есть, заполним их строкой \"Unknown\"\n",
    "df = df.fillna(\"Unknown\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tzt27tfjUpq"
   },
   "source": [
    "Разделите данные на обучающие и тестовые в соотношении 7 : 3 и `random_state=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xSLOA9tIj9Z6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9RrPUsJlL60"
   },
   "source": [
    "## Задание 2 Токенизация (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dz_b7Xopc_R"
   },
   "source": [
    "Постройте словарь на основе обучающей выборки и посчитайте количество встреч каждого токена с использованием самой простой токенизации - деления текстов по пробельным символам и приведение токенов в нижний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SFr67WOJphny",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'why': 654,\n",
       " 'we': 3787,\n",
       " 'still': 763,\n",
       " 'want': 487,\n",
       " 'to': 23373,\n",
       " 'buy': 748,\n",
       " 'so': 1837,\n",
       " 'much': 482,\n",
       " 'stuff': 106,\n",
       " 'during': 1908,\n",
       " 'quarantine': 154,\n",
       " 'https://t.co/1m881cwfuv': 1,\n",
       " '#shopping': 121,\n",
       " '#covid_19': 1660,\n",
       " '#online': 40,\n",
       " 'with': 4063,\n",
       " 'driving': 77,\n",
       " 'even': 682,\n",
       " 'more': 2008,\n",
       " 'usage': 22,\n",
       " 'a': 11737,\n",
       " 'strong': 93,\n",
       " 'strategy': 33,\n",
       " 'is': 7383,\n",
       " 'critical': 156,\n",
       " 'now': 1349,\n",
       " 'then': 435,\n",
       " 'ever': 179,\n",
       " 'luckily': 8,\n",
       " 'and': 14684,\n",
       " 'april': 163,\n",
       " '16': 36,\n",
       " 'webinar': 65,\n",
       " 'will': 2726,\n",
       " 'dive': 10,\n",
       " 'into': 666,\n",
       " 'growing': 84,\n",
       " 'app': 52,\n",
       " 'awareness': 32,\n",
       " 'targeting': 9,\n",
       " 'high': 408,\n",
       " 'lifetime': 4,\n",
       " 'value': 79,\n",
       " 'users': 19,\n",
       " '@canon_india': 16,\n",
       " 'i': 5340,\n",
       " 'am': 424,\n",
       " 'very': 418,\n",
       " 'happy..': 1,\n",
       " 'great': 409,\n",
       " 'job': 242,\n",
       " 'by': 2236,\n",
       " '#canonforcommunity': 5,\n",
       " 'https://t.co/z0intks34x': 1,\n",
       " 'the': 26815,\n",
       " 'u.s': 8,\n",
       " 'national': 123,\n",
       " 'debt': 68,\n",
       " 'likely': 170,\n",
       " 'exceed': 14,\n",
       " '$30': 7,\n",
       " 'trillion': 21,\n",
       " 'after': 886,\n",
       " 'unprecedented': 89,\n",
       " 'borrowing': 5,\n",
       " 'trump': 228,\n",
       " 'administration': 38,\n",
       " 'mnuchinã\\x82â\\x92s': 1,\n",
       " 'treasury': 3,\n",
       " '#coronavirus': 8223,\n",
       " 'crisis.': 162,\n",
       " 'federal': 99,\n",
       " 'reserve': 17,\n",
       " 'could': 640,\n",
       " 'be': 3570,\n",
       " 'doing': 508,\n",
       " 'cushion': 9,\n",
       " 'blow.': 4,\n",
       " 'consumer': 2245,\n",
       " 'led': 67,\n",
       " 'economy': 244,\n",
       " 'on': 5452,\n",
       " 'brink.': 1,\n",
       " 'finally': 91,\n",
       " 'got': 407,\n",
       " 'grocery': 3469,\n",
       " 'store.': 348,\n",
       " 'honestly,': 8,\n",
       " 'what': 1541,\n",
       " 'are': 7050,\n",
       " 'you': 5467,\n",
       " 'people': 3175,\n",
       " 'all': 2808,\n",
       " 'toilet': 824,\n",
       " 'paper?': 24,\n",
       " 'https://t.co/jmobv8z0u0': 1,\n",
       " 'friends:': 3,\n",
       " 'catholic': 7,\n",
       " \"university's\": 1,\n",
       " 'food': 3820,\n",
       " 'service': 305,\n",
       " 'workers': 1242,\n",
       " 'have': 3770,\n",
       " 'been': 1081,\n",
       " 'laid': 50,\n",
       " 'off': 472,\n",
       " 'without': 301,\n",
       " 'pay.': 14,\n",
       " '(by': 4,\n",
       " 'contrast,': 2,\n",
       " 'georgetown': 2,\n",
       " 'has': 2304,\n",
       " 'set': 146,\n",
       " 'an': 1417,\n",
       " 'example': 46,\n",
       " 'consistent': 7,\n",
       " 'social': 615,\n",
       " 'teaching.)': 1,\n",
       " 'please': 1061,\n",
       " 'sign': 106,\n",
       " 'rt.': 4,\n",
       " '@catholicpres': 1,\n",
       " '@catholicuniv': 1,\n",
       " 'https://t.co/evqby035wf': 1,\n",
       " \"it's\": 571,\n",
       " 'times': 372,\n",
       " 'like': 1550,\n",
       " 'these': 922,\n",
       " 'understand': 151,\n",
       " 'of': 13012,\n",
       " 'bidet.': 2,\n",
       " '#europe': 14,\n",
       " '#bidet': 6,\n",
       " '#toiletpaper': 691,\n",
       " 'regulatory': 11,\n",
       " 'litigation': 3,\n",
       " 'risks': 38,\n",
       " 'financial': 233,\n",
       " 'services': 263,\n",
       " 'providers': 38,\n",
       " 'highlighted': 9,\n",
       " 'in': 11198,\n",
       " 'ballard': 2,\n",
       " 'spahr': 2,\n",
       " 'covid-19': 3173,\n",
       " 'crisis': 713,\n",
       " 'fallout': 21,\n",
       " 'https://t.co/riqrhxxeim': 1,\n",
       " 'via': 687,\n",
       " '@@ballardspahrll': 1,\n",
       " '#training': 2,\n",
       " '#aca': 1,\n",
       " \"don't\": 551,\n",
       " 'panic': 1495,\n",
       " 'buying.': 77,\n",
       " \"i've\": 157,\n",
       " 'struggled': 10,\n",
       " 'get': 1759,\n",
       " 'basics': 19,\n",
       " 'as': 3694,\n",
       " 'emptying': 29,\n",
       " 'shelves.': 79,\n",
       " 'sensible': 20,\n",
       " \"aren't\": 61,\n",
       " 'shortage,': 13,\n",
       " 'just': 1540,\n",
       " 'shop': 471,\n",
       " 'time': 1136,\n",
       " 'restock': 42,\n",
       " 'if': 2142,\n",
       " \"we're\": 168,\n",
       " 'sensible,': 2,\n",
       " 'life': 244,\n",
       " 'slightly': 9,\n",
       " 'easier...take': 1,\n",
       " 'care': 401,\n",
       " '#coronacrisis': 423,\n",
       " 'at': 4642,\n",
       " 'least': 222,\n",
       " 'essential': 496,\n",
       " 'allowed,': 2,\n",
       " 'can': 2202,\n",
       " 'go': 1245,\n",
       " 'store': 3155,\n",
       " 'bank.': 8,\n",
       " 'itã\\x82â\\x92s': 459,\n",
       " 'ridiculous': 56,\n",
       " 'that': 3741,\n",
       " 'actually': 149,\n",
       " 'act': 102,\n",
       " 'going': 1141,\n",
       " 'those': 789,\n",
       " 'types': 25,\n",
       " 'places': 82,\n",
       " 'ã\\x82â\\x93necessaryã\\x82â\\x94': 1,\n",
       " 'stopped': 51,\n",
       " 'police.': 3,\n",
       " '?': 1320,\n",
       " '#covid19': 2471,\n",
       " '#quarantinelife': 112,\n",
       " 'queues': 54,\n",
       " 'outside': 151,\n",
       " 'supermarket': 3288,\n",
       " 'reserved': 10,\n",
       " 'for': 8566,\n",
       " 'elderly.': 8,\n",
       " 'britain,': 5,\n",
       " 'were': 566,\n",
       " 'better': 267,\n",
       " 'than': 891,\n",
       " 'this.': 92,\n",
       " 'https://t.co/0fmsmlgepm': 1,\n",
       " 'lt.': 3,\n",
       " 'gov.': 18,\n",
       " 'husted:': 1,\n",
       " '\"come': 4,\n",
       " 'people.': 113,\n",
       " 'that.\"': 4,\n",
       " 'hearing': 43,\n",
       " 'fight': 330,\n",
       " 'over': 786,\n",
       " 'paper': 587,\n",
       " 'from': 3045,\n",
       " 'one': 1074,\n",
       " 'american': 93,\n",
       " 'irishman': 1,\n",
       " 'others': 300,\n",
       " 'out': 2026,\n",
       " 'there,': 13,\n",
       " '#happystpatricksday!': 1,\n",
       " 'bought': 163,\n",
       " 'some': 1320,\n",
       " 'guiness': 1,\n",
       " 'corned': 2,\n",
       " 'beef': 32,\n",
       " 'cabbage': 2,\n",
       " 'other': 890,\n",
       " 'day': 521,\n",
       " 'since': 369,\n",
       " 'sadly': 19,\n",
       " 'cannot': 147,\n",
       " 'irish': 5,\n",
       " 'pub': 22,\n",
       " 'per': 246,\n",
       " 'tradition,': 2,\n",
       " 'thanks': 275,\n",
       " 'governor': 48,\n",
       " 'pritzker': 2,\n",
       " 'damn': 70,\n",
       " '@ufcw': 7,\n",
       " 'says': 369,\n",
       " '30': 79,\n",
       " 'died': 117,\n",
       " '#coronavirus.': 228,\n",
       " 'union': 38,\n",
       " 'reps': 6,\n",
       " 'consumers': 307,\n",
       " 'help': 1282,\n",
       " 'protect': 340,\n",
       " 'workers/the': 1,\n",
       " 'public.': 20,\n",
       " '-': 1429,\n",
       " 'wear': 182,\n",
       " 'mask': 330,\n",
       " 'when': 1343,\n",
       " 'shopping': 1621,\n",
       " 'touch': 75,\n",
       " 'few': 317,\n",
       " 'products': 427,\n",
       " 'possible': 143,\n",
       " 'throw': 27,\n",
       " 'used': 178,\n",
       " 'mask/gloves': 2,\n",
       " 'ã\\x82â\\x93major': 2,\n",
       " 'chains': 147,\n",
       " 'beginning': 83,\n",
       " 'report': 268,\n",
       " 'their': 1972,\n",
       " 'first': 475,\n",
       " 'coronavirus-related': 14,\n",
       " 'employee': 114,\n",
       " 'deaths,': 7,\n",
       " 'leading': 61,\n",
       " 'closures': 77,\n",
       " 'increasing': 121,\n",
       " 'anxiety': 90,\n",
       " 'among': 90,\n",
       " 'pandemic': 1026,\n",
       " 'intensifies': 8,\n",
       " 'across': 318,\n",
       " 'countryã\\x82â\\x94': 1,\n",
       " 'https://t.co/18v0pyhwb7': 1,\n",
       " 'my': 2445,\n",
       " 'story': 122,\n",
       " 'another': 246,\n",
       " 'aspect': 3,\n",
       " 'covid-19:': 134,\n",
       " 'banks': 244,\n",
       " 'face': 402,\n",
       " 'virus': 480,\n",
       " 'dilemma:': 3,\n",
       " 'demand,': 67,\n",
       " 'fewer': 28,\n",
       " 'volunteers': 68,\n",
       " 'https://t.co/ls0g86i8pu': 1,\n",
       " 'https://t.co/ofvkejff23': 1,\n",
       " 'walking': 68,\n",
       " 'around': 391,\n",
       " 'store,': 196,\n",
       " 'wearing': 190,\n",
       " 'was': 1384,\n",
       " 'weird.': 5,\n",
       " 'seeing': 214,\n",
       " 'mask,': 41,\n",
       " 'normal.': 28,\n",
       " 'sanitizing': 36,\n",
       " 'everything': 280,\n",
       " 'before': 433,\n",
       " 'putting': 166,\n",
       " 'it': 3150,\n",
       " 'away.': 26,\n",
       " 'weird': 37,\n",
       " 'time.': 158,\n",
       " '#azliving': 2,\n",
       " 'https://t.co/xoodgd2ulx': 1,\n",
       " 'point': 117,\n",
       " 're': 328,\n",
       " 'stock': 1063,\n",
       " 'piling': 36,\n",
       " 'live': 236,\n",
       " 'lifestyles': 1,\n",
       " 'eat': 125,\n",
       " 'lot': 262,\n",
       " 'don': 251,\n",
       " 't': 648,\n",
       " 'carry': 56,\n",
       " 'but': 2159,\n",
       " '70': 28,\n",
       " 'mother': 45,\n",
       " 'inherited': 1,\n",
       " 'wartime': 3,\n",
       " 'mentality': 2,\n",
       " 'doesn': 37,\n",
       " 'everyone': 600,\n",
       " '14': 49,\n",
       " 'days': 325,\n",
       " 'worth': 105,\n",
       " 'larder': 1,\n",
       " '1': 340,\n",
       " '2': 582,\n",
       " 'bay': 24,\n",
       " 'view': 42,\n",
       " 'distillery': 29,\n",
       " 'bottling': 1,\n",
       " 'hand': 1382,\n",
       " 'sanitizer': 1064,\n",
       " 'area': 125,\n",
       " 'nonprofits': 7,\n",
       " 'https://t.co/ogxu5ojpxh': 1,\n",
       " 'https://t.co/8cs3skukmn': 1,\n",
       " '#inspiration&gt;&gt;': 1,\n",
       " '#regram': 1,\n",
       " '#showcasing&gt;&gt;': 1,\n",
       " '#artwork': 1,\n",
       " '@karencantuq:': 1,\n",
       " 'title:': 2,\n",
       " '\"ready': 1,\n",
       " 'wipe': 59,\n",
       " 'coronavirus\"': 3,\n",
       " 'caption:': 2,\n",
       " '\"ps': 1,\n",
       " 'donã\\x82â\\x92t': 414,\n",
       " 'people\"': 2,\n",
       " '#stayinsideyourhouse': 1,\n",
       " 'follow&gt;&gt;': 1,\n",
       " '@authorship.me': 1,\n",
       " 'instagram:': 4,\n",
       " 'authorzine&gt;&gt;': 1,\n",
       " 'https://t.co/qo7tzfr0ih': 1,\n",
       " 'https://t.co/yu6kokta74': 1,\n",
       " 'spent': 43,\n",
       " 'trying': 307,\n",
       " 'book': 56,\n",
       " 'delivery': 686,\n",
       " 'any': 624,\n",
       " 'supermarket.': 204,\n",
       " 'there': 1219,\n",
       " 'no': 1898,\n",
       " 'availability': 30,\n",
       " '.': 454,\n",
       " 'self': 210,\n",
       " 'isolate': 52,\n",
       " '12': 78,\n",
       " 'weeks': 312,\n",
       " 'due': 1059,\n",
       " 'being': 827,\n",
       " 'immune': 59,\n",
       " 'supressed.': 1,\n",
       " 'how': 1850,\n",
       " 'supposed': 56,\n",
       " 'food?': 24,\n",
       " 'wonder': 67,\n",
       " 'stockpiled.': 4,\n",
       " 'help!': 15,\n",
       " '#coronacrisisuk': 49,\n",
       " '#stockpilinguk': 18,\n",
       " '#food': 158,\n",
       " 'complete': 61,\n",
       " 'madness': 22,\n",
       " '@borisjohnson': 78,\n",
       " '@susannareid100': 6,\n",
       " '@hollywills': 2,\n",
       " '@piersmorgan': 51,\n",
       " '@eamonnholmes': 1,\n",
       " '@ruthieel': 1,\n",
       " '@gmb': 15,\n",
       " '@bbcnews': 17,\n",
       " '@dailymailuk': 7,\n",
       " '#londonlockdown': 10,\n",
       " '#uklockdown': 22,\n",
       " '#covid-19': 191,\n",
       " 'https://t.co/dexxnx7ox3': 1,\n",
       " '\"forcing': 1,\n",
       " '50': 83,\n",
       " 'governors': 14,\n",
       " 'compete': 12,\n",
       " 'lifesaving': 5,\n",
       " 'equipment': 86,\n",
       " 'ã\\x82â\\x97': 141,\n",
       " 'hospitals': 81,\n",
       " 'pay': 329,\n",
       " 'exorbitant': 34,\n",
       " 'prices': 3891,\n",
       " 'only': 851,\n",
       " 'makes': 114,\n",
       " 'matters': 10,\n",
       " 'worse.\"': 1,\n",
       " 'bill': 67,\n",
       " 'gates:': 2,\n",
       " 'hereã\\x82â\\x92s': 59,\n",
       " 'make': 811,\n",
       " 'up': 1987,\n",
       " 'lost': 143,\n",
       " 'https://t.co/yh3rytrevk': 1,\n",
       " '#mondaymotivation': 16,\n",
       " 'iã\\x82â\\x92m': 414,\n",
       " 'privileged': 7,\n",
       " 'enough': 337,\n",
       " 'drive': 149,\n",
       " 'places.': 9,\n",
       " 'canã\\x82â\\x92t': 243,\n",
       " 'stop': 730,\n",
       " 'thinking': 98,\n",
       " 'about': 1726,\n",
       " 'easy': 74,\n",
       " 'access': 195,\n",
       " 'transport': 61,\n",
       " 'or': 2234,\n",
       " 'who': 1670,\n",
       " 'less': 212,\n",
       " 'able': 249,\n",
       " 'travel': 135,\n",
       " 'multiple': 43,\n",
       " 'shops.': 28,\n",
       " 'start': 201,\n",
       " '#stoppanicbuying': 130,\n",
       " '2/2': 8,\n",
       " 'especially': 161,\n",
       " 'whilst': 54,\n",
       " 'tesco': 51,\n",
       " 'own': 234,\n",
       " 'stores': 648,\n",
       " 'such': 269,\n",
       " 'leyton': 1,\n",
       " 'leytonstone': 2,\n",
       " 'frontline,': 4,\n",
       " 'dealing': 66,\n",
       " 'covid-19,': 311,\n",
       " 'restricted': 21,\n",
       " 'getting': 415,\n",
       " 'vulnerable': 275,\n",
       " 'difficult': 140,\n",
       " 'circumstances.': 8,\n",
       " 'every': 509,\n",
       " 'little': 208,\n",
       " 'helps!': 3,\n",
       " 'indeed!': 5,\n",
       " 'longer': 104,\n",
       " 'having': 257,\n",
       " 'cocktail': 3,\n",
       " 'parties,': 2,\n",
       " 'us': 1247,\n",
       " 'prefer': 15,\n",
       " 'stay': 895,\n",
       " 'sober': 2,\n",
       " 'find': 431,\n",
       " 'club': 24,\n",
       " 'soda': 4,\n",
       " 'local': 821,\n",
       " 'fourth': 6,\n",
       " 'emergency': 267,\n",
       " 'scammers': 113,\n",
       " 'using': 272,\n",
       " 'messages': 27,\n",
       " 'scam': 71,\n",
       " 'https://t.co/nzsthpcxre': 1,\n",
       " 'heaven': 3,\n",
       " 'hades': 1,\n",
       " 'judgement': 3,\n",
       " 'eternal': 2,\n",
       " 'hey': 89,\n",
       " 'wednesday': 42,\n",
       " '3': 364,\n",
       " 'helping': 213,\n",
       " 'free': 467,\n",
       " 'add': 66,\n",
       " 'link': 90,\n",
       " 'tell': 139,\n",
       " 'me': 920,\n",
       " 'which': 504,\n",
       " 'poll': 8,\n",
       " 'll': 75,\n",
       " 'feature': 9,\n",
       " 'blog': 63,\n",
       " '226k': 1,\n",
       " 'views': 11,\n",
       " 'tweet': 29,\n",
       " '54k': 1,\n",
       " 'followers': 12,\n",
       " 'mom': 48,\n",
       " 'found': 169,\n",
       " '#vintagetoiletpaper': 1,\n",
       " 'her': 377,\n",
       " 'basement.': 1,\n",
       " 'circa': 2,\n",
       " '1987.': 1,\n",
       " 'blue': 19,\n",
       " 'peach.': 1,\n",
       " 'told': 216,\n",
       " 'list': 173,\n",
       " '@ebay': 21,\n",
       " 'easy?': 1,\n",
       " '???': 182,\n",
       " 'https://t.co/2tvpmsaxox': 1,\n",
       " '@realdonaldtrump': 151,\n",
       " 'hear': 106,\n",
       " 'out,': 49,\n",
       " 'instead': 147,\n",
       " 'bailing': 6,\n",
       " 'corporations': 22,\n",
       " 'bailed': 2,\n",
       " 'everyoneã\\x82â\\x92s': 14,\n",
       " 'under': 239,\n",
       " '200k?': 1,\n",
       " 'bet': 31,\n",
       " 'would': 730,\n",
       " 'billions': 15,\n",
       " 'aaannnddd': 1,\n",
       " 'rebuy': 1,\n",
       " 'more!': 17,\n",
       " 'plus!': 1,\n",
       " 'our': 2460,\n",
       " 'tax': 64,\n",
       " 'mon': 3,\n",
       " 'yourself': 147,\n",
       " 'washing': 93,\n",
       " 'your': 2784,\n",
       " 'hands': 303,\n",
       " 'often': 60,\n",
       " 'soap': 161,\n",
       " 'water': 194,\n",
       " 'use': 572,\n",
       " '#wolverhampton': 1,\n",
       " 'https://t.co/e7ifbsqaxx': 1,\n",
       " 'two': 331,\n",
       " 'stories': 39,\n",
       " 'should': 875,\n",
       " 'mutually': 1,\n",
       " 'exclusive.': 1,\n",
       " \"couldn't\": 36,\n",
       " 'alleviate': 10,\n",
       " 'vice': 5,\n",
       " 'versa?': 1,\n",
       " 'https://t.co/01oc3pig5b': 1,\n",
       " 'https://t.co/omjr2atzhp': 1,\n",
       " \"here's\": 99,\n",
       " 'idea,': 5,\n",
       " 'become': 138,\n",
       " 'historian.': 1,\n",
       " 'write': 20,\n",
       " 'daily': 192,\n",
       " 'weekly': 60,\n",
       " 'diary': 7,\n",
       " 'grand': 12,\n",
       " 'children': 71,\n",
       " 'experiences.': 3,\n",
       " 'sacrifices,': 2,\n",
       " 'anecdotes,': 1,\n",
       " 'funny': 36,\n",
       " 'sad': 53,\n",
       " 'stories,': 1,\n",
       " 'recipes,': 3,\n",
       " 'photos': 38,\n",
       " 'newspaper': 3,\n",
       " 'clippings.': 1,\n",
       " 'imagine': 77,\n",
       " 'musings': 1,\n",
       " '1.': 77,\n",
       " 'need': 1549,\n",
       " 'media': 155,\n",
       " '#coronavirus...': 5,\n",
       " 'not': 2714,\n",
       " 'because': 902,\n",
       " 'news': 304,\n",
       " 'pictures': 26,\n",
       " 'take': 701,\n",
       " 'advantage': 174,\n",
       " 'of.': 11,\n",
       " '#instafood': 1,\n",
       " 'making': 404,\n",
       " 'restaurant': 88,\n",
       " 'animal': 43,\n",
       " 'shelters': 9,\n",
       " 'left': 211,\n",
       " 'starving': 10,\n",
       " 'buying': 911,\n",
       " 'consider': 122,\n",
       " 'donating': 84,\n",
       " 'through': 427,\n",
       " 'facebook': 45,\n",
       " '@theprojecttv': 1,\n",
       " '@mrbenjaminlaw': 1,\n",
       " 'okay': 28,\n",
       " 'empty': 407,\n",
       " 'shelves': 709,\n",
       " 'goods': 243,\n",
       " '&amp;': 2314,\n",
       " 'send': 112,\n",
       " 'them': 799,\n",
       " 'china!': 2,\n",
       " 'deprive': 3,\n",
       " 'medical': 303,\n",
       " 'supplies': 387,\n",
       " 'faulty': 3,\n",
       " 'covid': 1769,\n",
       " 'americans': 159,\n",
       " 'alarmed': 3,\n",
       " 'shelves,': 55,\n",
       " 'while': 638,\n",
       " 'suppliers': 55,\n",
       " 'retailers': 207,\n",
       " 'say': 350,\n",
       " 'they': 2309,\n",
       " 'struggling': 146,\n",
       " 'surging': 38,\n",
       " 'insist': 7,\n",
       " 'supply': 662,\n",
       " 'chain': 277,\n",
       " 'remains': 39,\n",
       " '@nytimes': 26,\n",
       " '#supplychain': 50,\n",
       " 'https://t.co/qro7avqbz5': 1,\n",
       " 'this': 4581,\n",
       " 'video': 152,\n",
       " 'seen': 258,\n",
       " 'many': 819,\n",
       " 'possible.': 26,\n",
       " 'nhs': 164,\n",
       " 'staff': 521,\n",
       " 'brave': 25,\n",
       " 'woman': 126,\n",
       " 'need,': 21,\n",
       " 'something': 203,\n",
       " 'needs': 276,\n",
       " 'done': 187,\n",
       " 'urgently.': 5,\n",
       " 'https://t.co/kh3kdyqd8t': 1,\n",
       " 'diageo': 1,\n",
       " 'hasnã\\x82â\\x92t': 13,\n",
       " 'clue.': 1,\n",
       " 'clear': 97,\n",
       " 'demonstraion': 1,\n",
       " 'remote': 31,\n",
       " 'consumer.#covid-19': 1,\n",
       " 'https://t.co/tfrsci5ysp': 1,\n",
       " 'picked': 18,\n",
       " 'hell': 54,\n",
       " 'back': 430,\n",
       " 'working': 594,\n",
       " 'rational,': 1,\n",
       " 'educated,': 2,\n",
       " 'respected': 13,\n",
       " 'members': 106,\n",
       " 'community': 243,\n",
       " 'non-perishable': 11,\n",
       " 'items': 439,\n",
       " 'bulk': 71,\n",
       " 'terrified': 12,\n",
       " 'facial': 5,\n",
       " 'expressions,': 1,\n",
       " 'eerie': 4,\n",
       " 'sense': 70,\n",
       " 'doomsday': 6,\n",
       " 'scenario': 11,\n",
       " \"isn't\": 88,\n",
       " 'far': 148,\n",
       " 'off.': 23,\n",
       " 'new': 885,\n",
       " 'study': 38,\n",
       " 'finds': 27,\n",
       " 'may': 525,\n",
       " 'surfaces': 37,\n",
       " 'previously': 23,\n",
       " 'thought.': 12,\n",
       " 'down': 609,\n",
       " 'cleanser,': 1,\n",
       " 'wash': 212,\n",
       " 'frequently': 19,\n",
       " 'sanitizer.': 101,\n",
       " 'safe!': 23,\n",
       " '#coronavirusupdate': 151,\n",
       " '#flatteningthecurve': 2,\n",
       " 'https://t.co/ghbayd7t0g': 1,\n",
       " 'claim': 43,\n",
       " 'support': 477,\n",
       " 'doctors,': 59,\n",
       " 'nurses,': 72,\n",
       " 'responders': 66,\n",
       " 'guard,': 1,\n",
       " 'staff,': 101,\n",
       " 'truck': 105,\n",
       " 'drivers,': 86,\n",
       " 'else': 189,\n",
       " 'continue': 261,\n",
       " 'ignore': 23,\n",
       " 'pleas': 4,\n",
       " 'home!': 21,\n",
       " '#stayhome': 229,\n",
       " '#flattenthecurve': 47,\n",
       " 'shops': 279,\n",
       " 'markets': 211,\n",
       " 'malls': 22,\n",
       " 'restaurants': 131,\n",
       " 'remain': 150,\n",
       " 'closed': 202,\n",
       " 'different': 123,\n",
       " 'cities': 34,\n",
       " 'pakistan': 20,\n",
       " 'country': 321,\n",
       " 'imposed': 22,\n",
       " 'ban': 45,\n",
       " 'movement': 42,\n",
       " 'spread': 514,\n",
       " 'following': 149,\n",
       " 'show': 135,\n",
       " 'roads': 15,\n",
       " 'karachi': 1,\n",
       " 'islamabad': 1,\n",
       " 'bannu': 1,\n",
       " 'online': 1648,\n",
       " '19': 2111,\n",
       " 'lockdown': 326,\n",
       " 'paddy': 1,\n",
       " 'drop': 235,\n",
       " 'closure': 30,\n",
       " 'inter': 3,\n",
       " 'state': 250,\n",
       " 'borders': 16,\n",
       " 'andhra': 1,\n",
       " 'pradesh': 2,\n",
       " '#trumppressconference': 6,\n",
       " 'never': 303,\n",
       " 'maga': 2,\n",
       " 'rally': 14,\n",
       " 'amp': 859,\n",
       " 'stand': 74,\n",
       " 'talking': 69,\n",
       " 'russia': 92,\n",
       " 'mbs': 9,\n",
       " 'oil': 900,\n",
       " 'gas': 361,\n",
       " 'cuts': 65,\n",
       " 'wtf': 31,\n",
       " 'notice': 48,\n",
       " 'press': 42,\n",
       " 'release': 23,\n",
       " 'induced': 13,\n",
       " '2020': 211,\n",
       " 'recession': 77,\n",
       " 'disrupt': 9,\n",
       " 'automotive': 6,\n",
       " 'electronics': 14,\n",
       " 'semiconductor': 2,\n",
       " 'infrastructure': 19,\n",
       " 'businesses': 342,\n",
       " 'lockdown:': 9,\n",
       " 'know': 641,\n",
       " 'options==&gt;': 1,\n",
       " 'https://t.co/qky8zps5oz': 1,\n",
       " '#21dayslockdown': 12,\n",
       " '#21daylockdown': 14,\n",
       " '#21dayslockdownindia': 1,\n",
       " '#coronavirusindia': 30,\n",
       " '#coronaviruslockdown': 71,\n",
       " 'idiots': 46,\n",
       " 'president': 104,\n",
       " 'also': 635,\n",
       " 'needed': 148,\n",
       " 'direct': 75,\n",
       " 'business': 445,\n",
       " 'situation,': 20,\n",
       " 'hike': 58,\n",
       " 'required': 50,\n",
       " 'safeguarding': 3,\n",
       " 'transmission': 28,\n",
       " 'packet': 8,\n",
       " 'facemasks': 7,\n",
       " '@': 111,\n",
       " '150k,': 1,\n",
       " 'chloroquine': 19,\n",
       " '100k': 5,\n",
       " 'right,': 9,\n",
       " 'see': 756,\n",
       " 'greedy': 60,\n",
       " '*duckers*': 1,\n",
       " 'stockpiled': 10,\n",
       " 'all!': 12,\n",
       " '#convid19uk': 23,\n",
       " '#stopstockpiling': 44,\n",
       " 'call': 276,\n",
       " 'bollocks': 6,\n",
       " 'one.': 30,\n",
       " 'fair': 53,\n",
       " 'amount': 98,\n",
       " 'ppl': 120,\n",
       " 'buyin': 1,\n",
       " 'immediately': 51,\n",
       " 'years': 146,\n",
       " 'brexit': 18,\n",
       " 'n': 90,\n",
       " 'general': 94,\n",
       " 'skintness.': 1,\n",
       " 'its': 674,\n",
       " 'fucking': 128,\n",
       " 'buyers.': 7,\n",
       " \"'accidental\": 3,\n",
       " \"hoarders'\": 2,\n",
       " 'causing': 76,\n",
       " 'shortages': 146,\n",
       " 'https://t.co/q2nslsf6ke': 1,\n",
       " 'sent': 68,\n",
       " '@updayuk': 5,\n",
       " \"today's\": 33,\n",
       " 'news:': 26,\n",
       " 'pressured': 3,\n",
       " 'close': 250,\n",
       " 'affects': 19,\n",
       " 'beauty': 22,\n",
       " 'industry': 234,\n",
       " 'retail': 610,\n",
       " 'age': 60,\n",
       " 'coronavirus': 970,\n",
       " 'j.c.': 1,\n",
       " 'penney': 1,\n",
       " 'brings': 23,\n",
       " 'interactive': 6,\n",
       " 'style': 15,\n",
       " 'fitting': 7,\n",
       " 'rooms': 10,\n",
       " '#coronapocalypse': 23,\n",
       " '#ecommerce': 79,\n",
       " '#retail': 180,\n",
       " '#dtc': 3,\n",
       " 'https://t.co/rafj2l2ceq': 2,\n",
       " 'https://t.co/tgoar4fhl1': 1,\n",
       " 'love': 146,\n",
       " 'this!': 23,\n",
       " 'victoria': 5,\n",
       " 'helps': 50,\n",
       " 'production': 217,\n",
       " '1st': 64,\n",
       " 'wwii,': 7,\n",
       " 'demand': 1345,\n",
       " '|': 279,\n",
       " 'cbc': 17,\n",
       " 'https://t.co/75vb12pbap': 1,\n",
       " '@cityoftoronto': 1,\n",
       " '@johntory': 2,\n",
       " 'bank': 211,\n",
       " 'grateful': 64,\n",
       " 'donations': 84,\n",
       " 'sees': 44,\n",
       " 'spike': 46,\n",
       " '#covid2019': 915,\n",
       " \"doesn't\": 94,\n",
       " 'discriminate.': 1,\n",
       " 'society': 78,\n",
       " 'healthcare': 214,\n",
       " 'system': 132,\n",
       " 'does.': 2,\n",
       " 'minimum': 65,\n",
       " 'wage': 52,\n",
       " 'grocery-store/warehouse': 1,\n",
       " 'workers,': 280,\n",
       " 'migrant': 9,\n",
       " 'transported': 1,\n",
       " 'fields': 16,\n",
       " 'crowded': 51,\n",
       " 'trucks,': 2,\n",
       " 'living': 100,\n",
       " 'public': 386,\n",
       " 'housing': 65,\n",
       " 'w/mold': 1,\n",
       " 'causes': 48,\n",
       " 'asthma': 18,\n",
       " 'disproportionately': 6,\n",
       " 'risk': 397,\n",
       " 'waiting': 115,\n",
       " 'line': 291,\n",
       " 'order': 337,\n",
       " 'practice': 80,\n",
       " 'safe': 487,\n",
       " '#socialdistancing': 427,\n",
       " ',': 187,\n",
       " 'sure': 288,\n",
       " 'youre': 4,\n",
       " 'fit': 17,\n",
       " 'corpse': 3,\n",
       " 'between': 152,\n",
       " 'person': 207,\n",
       " 'front': 231,\n",
       " 'you.': 117,\n",
       " 'added': 39,\n",
       " 'accuracy,': 1,\n",
       " 'bring': 137,\n",
       " 'body': 26,\n",
       " 'went': 378,\n",
       " 'usual': 62,\n",
       " 'had': 660,\n",
       " 'door': 57,\n",
       " '(100': 1,\n",
       " 'store)': 14,\n",
       " 'right': 455,\n",
       " 'needed.': 21,\n",
       " 'prevent': 152,\n",
       " 'it,': 87,\n",
       " 'venezuelan.': 1,\n",
       " 'article:': 10,\n",
       " 'health': 540,\n",
       " 'share': 254,\n",
       " 'begin': 31,\n",
       " 'recovery': 51,\n",
       " 'https://t.co/auxib44pom': 1,\n",
       " 'yesterday': 113,\n",
       " 'took': 95,\n",
       " 'n95': 47,\n",
       " 'masks,': 87,\n",
       " 'gloves': 216,\n",
       " 'revera': 1,\n",
       " 'mckenzie': 1,\n",
       " 'towne': 2,\n",
       " 'retirement': 8,\n",
       " 'brenda': 1,\n",
       " 'strafford': 1,\n",
       " 'foundation.': 2,\n",
       " '#2019ncov': 4,\n",
       " '#sarscov2': 22,\n",
       " '#albertafireflood': 1,\n",
       " '#restoration': 1,\n",
       " '#cleaning': 6,\n",
       " '#sanatizing': 1,\n",
       " '#heretohelp': 2,\n",
       " '#supportlocal': 10,\n",
       " '#calgary': 4,\n",
       " '#yyc': 7,\n",
       " '#supportlocalbusiness': 5,\n",
       " 'loads': 28,\n",
       " 'emails': 37,\n",
       " 'companies': 393,\n",
       " 'last': 462,\n",
       " 'saying': 153,\n",
       " 'customers': 451,\n",
       " '#sky': 2,\n",
       " 'true': 72,\n",
       " 'colours': 4,\n",
       " 'increase': 348,\n",
       " '#noshame': 1,\n",
       " '#nosense': 1,\n",
       " '#cancelsky': 1,\n",
       " 'https://t.co/8mrz0kdmez': 1,\n",
       " 'marketers': 16,\n",
       " 'friends,': 10,\n",
       " 'good': 586,\n",
       " 'article': 112,\n",
       " '@mckinsey': 22,\n",
       " 'regarding': 90,\n",
       " 'customer': 129,\n",
       " 'sentiment': 69,\n",
       " 'ready': 107,\n",
       " 'change': 174,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = {}\n",
    "tweets = train[\"OriginalTweet\"].apply(lambda x: x.lower().split())\n",
    "for i in tweets:\n",
    "    for j in i:\n",
    "        if j in td.keys():\n",
    "            td[j] += 1\n",
    "        else:\n",
    "            td[j] = 1\n",
    "td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe0h2Jqkpnao"
   },
   "source": [
    "Какой размер словаря получился?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "umyENA7EpokD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79755"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d2G1Z-Qpqkd"
   },
   "source": [
    "Выведите 10 самых популярных токенов с количеством встреч каждого из них. Объясните, почему именно эти токены в топе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Impi32a_pssg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 26815),\n",
       " ('to', 23373),\n",
       " ('and', 14684),\n",
       " ('of', 13012),\n",
       " ('a', 11737),\n",
       " ('in', 11198),\n",
       " ('for', 8566),\n",
       " ('#coronavirus', 8223),\n",
       " ('is', 7383),\n",
       " ('are', 7050)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(td.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtuJCD0ApuFd"
   },
   "source": [
    "**Ответ:** Именно эти токены в топе, потому что они (все кроме одного) представляют из себя важные грамматические структуры английского языка, встречающиеся практически в любом предложении: артикли, предлоги и формы глагола to be. Кроме них в топ входит '#coronavirus', но и это логично - выборка ведь состоит только из твитов о коронавирусе, поэтому данный хэштег ожидаемо очень часто используем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7DTQDkWsVYp"
   },
   "source": [
    "Удалите стоп-слова из словаря и выведите новый топ-10 токенов (и количество встреч) по популярности.  Что можно сказать  о нем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8csSAdgTsnFx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/striker_isp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#coronavirus', 8223),\n",
       " ('prices', 3891),\n",
       " ('food', 3820),\n",
       " ('grocery', 3469),\n",
       " ('supermarket', 3288),\n",
       " ('people', 3175),\n",
       " ('covid-19', 3173),\n",
       " ('store', 3155),\n",
       " ('#covid19', 2471),\n",
       " ('&amp;', 2314)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in stopwords.words('english'):\n",
    "    if i in td.keys():\n",
    "        td.pop(i)\n",
    "sorted(td.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZH0x2Lzs-Dh"
   },
   "source": [
    "**Ответ:** Все грамматические слова были удалены. Хэштег, разумеется, остался. Из остального, часто упоминаются prices, food, grocery, supermarket, store - что указывает на проблемы с ценами в магазинах, когда люди подняли спрос на повседневные товары, закупившись ими в начале пандемии. Также, разумеется, часто встречается covid-19 и #covid-19, по аналогии с уже присутствовавшим хэштегом. Частота использования токена people тоже логична, ведь твиты о коронавирусе - это твиты о чем-то глобальном, затрагивающем много людей, и о действиях этого множества людей. Также присутствует токен \\&amp;, который предположительно представляет из себя эмодзи или некий символ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKSGRyI-uor0"
   },
   "source": [
    "Также выведите 20 самых непопулярных слов (если самых непопулярных слов больше выведите любые 20 из них) Почему эти токены непопулярны, требуется ли как-то дополнительно работать с ними?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "moArbwfvun9t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://t.co/1m881cwfuv', 1),\n",
       " ('happy..', 1),\n",
       " ('https://t.co/z0intks34x', 1),\n",
       " ('mnuchinã\\x82â\\x92s', 1),\n",
       " ('brink.', 1),\n",
       " ('https://t.co/jmobv8z0u0', 1),\n",
       " (\"university's\", 1),\n",
       " ('teaching.)', 1),\n",
       " ('@catholicpres', 1),\n",
       " ('@catholicuniv', 1),\n",
       " ('https://t.co/evqby035wf', 1),\n",
       " ('https://t.co/riqrhxxeim', 1),\n",
       " ('@@ballardspahrll', 1),\n",
       " ('#aca', 1),\n",
       " ('easier...take', 1),\n",
       " ('ã\\x82â\\x93necessaryã\\x82â\\x94', 1),\n",
       " ('https://t.co/0fmsmlgepm', 1),\n",
       " ('husted:', 1),\n",
       " ('irishman', 1),\n",
       " ('#happystpatricksday!', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(td.items(), key=lambda x: x[1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRp3J1gQunlR"
   },
   "source": [
    "**Ответ:** Это, в основном, ссылки, юзернеймы и т.д. И конечно они не популярны, ведь это могут быть ссылки на никому не известные ресурсы или условно тэги юзернеймов друзей с 0.00001 подписчиком, которые делаются один раз одним человеком. В целом, для целей машинного обучения эти ссылки можно попытаться убрать, ведь они (по крайней мере, очевидным образом) не влияют на эмоциональную окраску твитов. С другой стороны, приведу пример: если какая-то ссылка в твите A указывает на другой твит B, который можно явно охарактеризовать как негативный, а в твите A нет ничего кроме ссылки и слова \"Yes\", то охарактеризовать этот твит как негативный можно только при обладании этой ссылкой. Поэтому тут все зависит от того, как мы решим действовать - включать в анализ твиты-ответы как выражающие согласную с изначальным твитом эмоцию или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx9LQOSPzvjV"
   },
   "source": [
    "Теперь воспользуемся токенайзером получше - TweetTokenizer из библиотеки nltk. Примените его и посмотрите на топ-10 популярных слов. Чем он отличается от топа, который получался раньше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2G1UkyVxzvFY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 24337),\n",
       " ('.', 24118),\n",
       " ('to', 22933),\n",
       " (',', 17571),\n",
       " ('and', 14354),\n",
       " ('of', 12904),\n",
       " ('a', 11045),\n",
       " ('in', 10573),\n",
       " ('?', 9524),\n",
       " ('for', 8228)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "t = TweetTokenizer()\n",
    "td_tok = {}\n",
    "for i in train[\"OriginalTweet\"]:\n",
    "    tweet = t.tokenize(i)\n",
    "    for j in tweet:\n",
    "        if j in td_tok.keys():\n",
    "            td_tok[j] += 1\n",
    "        else:\n",
    "            td_tok[j] = 1\n",
    "sorted(td_tok.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50eVUnJN1Zxl"
   },
   "source": [
    "**Ответ:** Этот топ отличается тем, что включает в себя знаки препинания, потому что, видимо, данный токенизатор выделяет пунктуацию как отдельные токены. Ну а вхождение знаков препинания в топ объяснимо так же, как и с грамматическими словами - некоторые из знаков пунктуации так или иначе присутствуют почти в любом предложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gqQgiMs11bs"
   },
   "source": [
    "Удалите из словаря стоп-слова и пунктуацию, посмотрите на новый топ-10 слов с количеством встреч, есть ли теперь в нем что-то не похожее на слова?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0yHWdFrp0Mup",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Â', 7415),\n",
       " ('\\x82', 7311),\n",
       " ('19', 7167),\n",
       " ('#coronavirus', 7143),\n",
       " ('I', 5235),\n",
       " ('\\x92', 4372),\n",
       " ('prices', 4281),\n",
       " ('COVID', 4218),\n",
       " ('food', 3795),\n",
       " ('store', 3691)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "for i in stopwords.words('english'):\n",
    "    if i in td_tok.keys():\n",
    "        td_tok.pop(i)\n",
    "        \n",
    "for i in punctuation:\n",
    "    if i in td_tok.keys():\n",
    "        td_tok.pop(i)\n",
    "\n",
    "sorted(td_tok.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZJqXELP_Yxy"
   },
   "source": [
    "**Ответ:** Некоторые токены те же, что и в токенизации по пробелам выше после удаления стоп-слов. Также добавилось число 19 (предположительно, от твитов, которые писали \"covid 19\" через пробел), добавился COVID заглавными буквами (ранее такого токена не было, так как при токенизации твиты были приведены в нижний регистр) и добавилось местоимение I, встречающееся почти в любом предложении, автор которого хочет что-то сказать о себе (ранее этого местоимения в топе не было, возможно потому что оно не отделялось от конструкций по типу I'm или I'd и воспринималось с ними как одно целое). Еще появились токены Â, \\x82 и \\x92, первое из которых точно, а второе и третье предположительно, являются символами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzXjMsSB_kXB"
   },
   "source": [
    "Удалите из словаря токены из одного символа, с позицией в таблице Unicode 128 и более (`ord(x) >= 128`)\n",
    "\n",
    "Выведите топ-10 самых популярных и топ-20 непопулярных слов. Чем полученные топы отличаются от итоговых топов, полученных при использовании токенизации по пробелам? Что теперь лучше, а что хуже?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1695hlkS_1-J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('19', 7167),\n",
       " ('#coronavirus', 7143),\n",
       " ('I', 5235),\n",
       " ('prices', 4281),\n",
       " ('COVID', 4218),\n",
       " ('food', 3795),\n",
       " ('store', 3691),\n",
       " ('supermarket', 3373),\n",
       " ('grocery', 3083),\n",
       " ('people', 3047)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in td_tok.copy().keys():\n",
    "    if len(i) == 1 and ord(i) >= 128:\n",
    "        td_tok.pop(i)\n",
    "\n",
    "sorted(td_tok.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://t.co/1m881CwFUv', 1),\n",
       " ('https://t.co/Z0intkS34x', 1),\n",
       " ('MnuchinÃ', 1),\n",
       " ('https://t.co/JmoBv8z0U0', 1),\n",
       " (\"University's\", 1),\n",
       " ('@CatholicPres', 1),\n",
       " ('@CatholicUniv', 1),\n",
       " ('https://t.co/EvQby035wF', 1),\n",
       " ('https://t.co/rIQrhxxeIM', 1),\n",
       " ('@BallardSpahrLL', 1),\n",
       " ('#training', 1),\n",
       " ('#aca', 1),\n",
       " ('https://t.co/0FmSmlGePM', 1),\n",
       " ('Irishman', 1),\n",
       " ('#HappyStPatricksDay', 1),\n",
       " ('Guiness', 1),\n",
       " ('https://t.co/18V0PYHwb7', 1),\n",
       " ('https://t.co/LS0g86i8PU', 1),\n",
       " ('https://t.co/oFVkejfF23', 1),\n",
       " ('https://t.co/Xoodgd2uLx', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(td_tok.items(), key=lambda x: x[1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzjHAKIlDvc6"
   },
   "source": [
    "**Ответ:** Полученные топы отличаются от итоговых при токенизации по пробелам тем, что они учитывают регистр, способны отделить слово от привязанной к нему сокращенной грамматической структуры ('m, 'd) - это о топ-10 самых частых. А топ-20 самых нечастых по сути отличается незначительно - в нем разве что стало больше хэштегов.\n",
    "Я бы сказал, что топ-10 лучших стал лучше с твит-токенизатором (плюс: упомянутая способность отделить слово от сокращенной грамматической структуры; а минус, что разными считаются одинаковые слова в разном регистре, в рамках нашей задачи превращается в плюс - ведь, например, написание слова заглавными буквами выражает определенную эмоцию). И топ-20 непопулярных, пожалуй, тоже был улучшен твит-токенизатором, так как теперь в нем выделено больше хэштегов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcDf9_6HB2zm"
   },
   "source": [
    "Выведите топ-10 популярных хештегов с количеством встреч. Что можно сказать о них?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zk4fygCUBw3l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#coronavirus', 8223),\n",
       " ('#covid19', 2471),\n",
       " ('#covid_19', 1660),\n",
       " ('#covid2019', 915),\n",
       " ('#toiletpaper', 691),\n",
       " ('#socialdistancing', 427),\n",
       " ('#coronacrisis', 423),\n",
       " ('#covid?19', 418),\n",
       " ('#coronaviruspandemic', 245),\n",
       " ('#pandemic', 232)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htd = {}\n",
    "tweets = train[\"OriginalTweet\"].apply(lambda x: x.lower().split())\n",
    "for i in tweets:\n",
    "    for j in i:\n",
    "        if j[0] == '#':\n",
    "            if j in htd.keys():\n",
    "                htd[j] += 1\n",
    "            else:\n",
    "                htd[j] = 1\n",
    "sorted(htd.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6NeNWBkDxM7"
   },
   "source": [
    "**Ответ:** Все хэштеги либо являются непосредственными синонимами (или различными написаниями) названия вируса covid-19 и связанной с ним пандемии, либо отсылают к кейсам пандемии covid-19 (известный спрос на туалетную бумагу при кризисах (в частности, при пандемии covid-19), социальная дистанция)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLYBg7caD5GA"
   },
   "source": [
    "То же самое проделайте для ссылок на сайт https://t.co Сравнима ли популярность ссылок с популярностью хештегов? Будет ли информация о ссылке на конкретную страницу полезна?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MXbm1oeaCK9S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://t.co/oxa7swtond', 5),\n",
       " ('https://t.co/gp3eusapl8', 4),\n",
       " ('https://t.co/deftrui1pfã\\x82â', 3),\n",
       " ('https://t.co/wrlhyzizaa', 3),\n",
       " ('https://t.co/kuwipf1kqw', 3),\n",
       " ('https://t.co/zjnrx6dkkn', 3),\n",
       " ('https://t.co/3gbbdpdjat', 3),\n",
       " ('https://t.co/e2znxajpre', 3),\n",
       " ('https://t.co/catkegayoy', 3),\n",
       " ('https://t.co/g63rp042ho', 3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltd = {}\n",
    "tweets = train[\"OriginalTweet\"].apply(lambda x: x.lower().split())\n",
    "for i in tweets:\n",
    "    for j in i:\n",
    "        if j[:12] == 'https://t.co':\n",
    "            if j in ltd.keys():\n",
    "                ltd[j] += 1\n",
    "            else:\n",
    "                ltd[j] = 1\n",
    "sorted(ltd.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at6lRYZ8A07N"
   },
   "source": [
    "**Ответ:** # Популярность ссылок абсолютно не сравнима с популярностью хэштегов. И это логично, ведь суть хэштего в массовом обсуждении тем, в то время как ссылки зачастую публикуют на отдельные точечные ресурсы. Поэтому информация о ссылке на конкретную страницу не будет полезна, ведь одинаковых ссылок слишком мало в выборке для должного обучения на них. Хотя, конечно, так же как и в примере с твитом-ответом, содержимое ссылки может помочь в определении эмоциональной окраски твита, если оно является эмоционально окрашенным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOGdUU1kBU1D"
   },
   "source": [
    "Используем опыт предыдущих экспериментов и напишем собственный токенайзер, улучшив TweetTokenizer. Функция tokenize должна:\n",
    "\n",
    "\n",
    "\n",
    "*   Привести текст в нижний регистр\n",
    "*   Применить TweetTokenizer для изначального выделения токенов\n",
    "*   Удалить стоп-слова, пунктуацию, токены из одного символа, с позицией в таблице Unicode 128 и более и ссылки на t.co\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ctEsB6xkFrrK"
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    t = TweetTokenizer()\n",
    "    tokens = t.tokenize(text)\n",
    "    \n",
    "    for i in stopwords.words('english'):\n",
    "        while i in tokens:\n",
    "            tokens.remove(i)\n",
    "    for i in punctuation:\n",
    "        while i in tokens:\n",
    "            tokens.remove(i)\n",
    "    for i in tokens.copy():\n",
    "        if len(i) == 1 and ord(i) >= 128:\n",
    "            tokens.remove(i)\n",
    "    for i in tokens.copy():\n",
    "        if i[:12] == 'с':\n",
    "            tokens.remove(i)\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwbgtYkJGYym",
    "outputId": "5808765b-3448-45e6-ccc1-7cd65f6371ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'text', '@sample_text', '#sampletext']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wURVABmXHk97"
   },
   "source": [
    "## Задание 3 Векторизация текстов (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H44iXkoHIQfN"
   },
   "source": [
    "Обучите CountVectorizer с использованием custom_tokenizer в качестве токенайзера. Как размер полученного словаря соотносится с размером изначального словаря из начала задания 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHn_limQl3BI",
    "outputId": "8e9c1826-319f-4376-f06e-c30c2eb82648"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "cvft = cv.fit_transform(train[\"OriginalTweet\"])\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsfmaSGoItUm"
   },
   "source": [
    "**Ответ:** Полученный словарь сильноо меньше изначального словаря из задания 2... почти в 2 раза. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm6UHNmqKZT0"
   },
   "source": [
    "Посмотрим на какой-нибудь конкретный твитт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "aJVjjfqOJh8m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nice one @SkyNews lets not panic but show ppl in france queueing for food!!! #CoronavirusOutbreak #COVID2019 brainless!! Ffs',\n",
       " 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 9023\n",
    "train.iloc[ind]['OriginalTweet'], train.iloc[ind]['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBMIHBI5KdaS"
   },
   "source": [
    "Автор твитта не доволен ситуацией с едой во Франции и текст имеет резко негативную окраску.\n",
    "\n",
    "Примените обученный CountVectorizer для векторизации данного текста, и попытайтесь определить самый важный токен и самый неважный токен (токен, компонента которого в векторе максимальна/минимальна, без учета 0). Хорошо ли они определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7NcAllaEKsJj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1833)\t1\n",
      "  (0, 2046)\t1\n",
      "  (0, 16658)\t1\n",
      "  (0, 20553)\t1\n",
      "  (0, 26665)\t1\n",
      "  (0, 27042)\t1\n",
      "  (0, 27233)\t1\n",
      "  (0, 31579)\t1\n",
      "  (0, 34079)\t1\n",
      "  (0, 34688)\t1\n",
      "  (0, 35257)\t1\n",
      "  (0, 36413)\t1\n",
      "  (0, 37229)\t1\n",
      "  (0, 39919)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cv.transform([train.iloc[ind][\"OriginalTweet\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpEsl1k_NF4T"
   },
   "source": [
    "**Ответ:** Определилось совсем не хорошо (не определилось). У всех токенов компонента = 1. А не определились, потому что все токены встречаются в предложении только по 1 разу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4DsEQpLO3J6"
   },
   "source": [
    "Теперь примените TfidfVectorizer и  определите самый важный/неважный токены. Хорошо ли определились, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "uSNzdK3ENGB3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 39919)\t0.24406492401820118\n",
      "  (0, 37229)\t0.35434556333216544\n",
      "  (0, 36413)\t0.2550064610386691\n",
      "  (0, 35257)\t0.14759470306326164\n",
      "  (0, 34688)\t0.16306722855395073\n",
      "  (0, 34079)\t0.2542729176022132\n",
      "  (0, 31579)\t0.30121070136861045\n",
      "  (0, 27233)\t0.32047314046539654\n",
      "  (0, 27042)\t0.11328893069250721\n",
      "  (0, 26665)\t0.3244741764513268\n",
      "  (0, 20553)\t0.3867641170466375\n",
      "  (0, 16658)\t0.31042634466284263\n",
      "  (0, 2046)\t0.16825192939361902\n",
      "  (0, 1833)\t0.22584265007428544\n",
      "###covid-19\n",
      "brainless\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "tvft = tv.fit_transform(train[\"OriginalTweet\"])\n",
    "\n",
    "print(tv.transform([train.iloc[ind][\"OriginalTweet\"]]))\n",
    "print(tv.get_feature_names_out()[tv.transform([train.iloc[ind][\"OriginalTweet\"]]).argmin()]) # самый неважный\n",
    "print(tv.get_feature_names_out()[tv.transform([train.iloc[ind][\"OriginalTweet\"]]).argmax()]) # самый важный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYao_UhqQADm"
   },
   "source": [
    "**Ответ:** Самый важный - brainless. Самый неважный - ###covid-19. Определились хорошо, потому что в tf-idf важна не только частота в одном твите, но и частота во всех твитах в выборке, что и делает значения различными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGRJPqfWSesQ"
   },
   "source": [
    "Найдите какой-нибудь положительно окрашенный твитт, где TfidfVectorizer хорошо (полезно для определения окраски) выделяет важный токен, поясните пример.\n",
    "\n",
    "*Подсказка:* явно положительные твитты можно искать при помощи положительных слов (good, great, amazing и т. д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "bRbQ2CHiSuJI",
    "outputId": "c4b34a7d-1076-4e1e-ad5c-9466fd2097c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11674</th>\n",
       "      <td>17953</td>\n",
       "      <td>62905</td>\n",
       "      <td>Essex</td>\n",
       "      <td>21-03-2020</td>\n",
       "      <td>Thank you so much @waitrose you have been amaz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29904</th>\n",
       "      <td>40517</td>\n",
       "      <td>85469</td>\n",
       "      <td>India</td>\n",
       "      <td>09-04-2020</td>\n",
       "      <td>@Canon_India Coming together for a amazing cau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23318</th>\n",
       "      <td>32289</td>\n",
       "      <td>77241</td>\n",
       "      <td>Dublin City, Ireland</td>\n",
       "      <td>04-04-2020</td>\n",
       "      <td>Healthcare workers are amazing during this #CO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>11177</td>\n",
       "      <td>56129</td>\n",
       "      <td>Ottawa Hills, Ohio</td>\n",
       "      <td>19-03-2020</td>\n",
       "      <td>#SickLeave #Petition | #Kroger is the largest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21299</th>\n",
       "      <td>29778</td>\n",
       "      <td>74730</td>\n",
       "      <td>Morrisville, NC</td>\n",
       "      <td>01-04-2020</td>\n",
       "      <td>We've got newly updated info about online shop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>16499</td>\n",
       "      <td>61451</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>21-03-2020</td>\n",
       "      <td>This Covid-19 is really an amazing ÃÂselecti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13355</th>\n",
       "      <td>20006</td>\n",
       "      <td>64958</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>22-03-2020</td>\n",
       "      <td>\"This particular edition of Writer's Lounge is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>8135</td>\n",
       "      <td>53087</td>\n",
       "      <td>Surrey, Sussex or Cornwall</td>\n",
       "      <td>18-03-2020</td>\n",
       "      <td>Spare a thought for our amazing doctors and nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19919</th>\n",
       "      <td>28079</td>\n",
       "      <td>73031</td>\n",
       "      <td>Newbury, Berkshire, UK</td>\n",
       "      <td>26-03-2020</td>\n",
       "      <td>The amazing and have managed to get production...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24592</th>\n",
       "      <td>33890</td>\n",
       "      <td>78842</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>As ridiculous as this post is... We found some...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>8683</td>\n",
       "      <td>53635</td>\n",
       "      <td>Co. Wicklow</td>\n",
       "      <td>18-03-2020</td>\n",
       "      <td>In the last 24 hours, 24,000 people have conta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25256</th>\n",
       "      <td>34736</td>\n",
       "      <td>79688</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>06-04-2020</td>\n",
       "      <td>Some amazing holiday deals going for later in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23018</th>\n",
       "      <td>31918</td>\n",
       "      <td>76870</td>\n",
       "      <td>Karachi, Pakistan</td>\n",
       "      <td>04-04-2020</td>\n",
       "      <td>Face Mask (Pack of 5) ÃÂ Meeting the need of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>13757</td>\n",
       "      <td>58709</td>\n",
       "      <td>Wrightington</td>\n",
       "      <td>20-03-2020</td>\n",
       "      <td>The support from customers this week has been ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18271</th>\n",
       "      <td>26029</td>\n",
       "      <td>70981</td>\n",
       "      <td>Abubakar koko road, Abuja Nige</td>\n",
       "      <td>25-03-2020</td>\n",
       "      <td>Why not stay home and be safe?\\r\\r\\n\\r\\r\\nWhil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                        Location     TweetAt  \\\n",
       "11674     17953       62905                           Essex  21-03-2020   \n",
       "29904     40517       85469                           India  09-04-2020   \n",
       "23318     32289       77241            Dublin City, Ireland  04-04-2020   \n",
       "6074      11177       56129              Ottawa Hills, Ohio  19-03-2020   \n",
       "21299     29778       74730                 Morrisville, NC  01-04-2020   \n",
       "10468     16499       61451                         Unknown  21-03-2020   \n",
       "13355     20006       64958                 Los Angeles, CA  22-03-2020   \n",
       "3567       8135       53087      Surrey, Sussex or Cornwall  18-03-2020   \n",
       "19919     28079       73031          Newbury, Berkshire, UK  26-03-2020   \n",
       "24592     33890       78842                         Unknown  06-04-2020   \n",
       "4016       8683       53635                     Co. Wicklow  18-03-2020   \n",
       "25256     34736       79688                       Singapore  06-04-2020   \n",
       "23018     31918       76870               Karachi, Pakistan  04-04-2020   \n",
       "8199      13757       58709                   Wrightington   20-03-2020   \n",
       "18271     26029       70981  Abubakar koko road, Abuja Nige  25-03-2020   \n",
       "\n",
       "                                           OriginalTweet  Sentiment  \n",
       "11674  Thank you so much @waitrose you have been amaz...          1  \n",
       "29904  @Canon_India Coming together for a amazing cau...          1  \n",
       "23318  Healthcare workers are amazing during this #CO...          1  \n",
       "6074   #SickLeave #Petition | #Kroger is the largest ...          1  \n",
       "21299  We've got newly updated info about online shop...          1  \n",
       "10468  This Covid-19 is really an amazing ÃÂselecti...          1  \n",
       "13355  \"This particular edition of Writer's Lounge is...          1  \n",
       "3567   Spare a thought for our amazing doctors and nu...          1  \n",
       "19919  The amazing and have managed to get production...          1  \n",
       "24592  As ridiculous as this post is... We found some...          1  \n",
       "4016   In the last 24 hours, 24,000 people have conta...          1  \n",
       "25256  Some amazing holiday deals going for later in ...          1  \n",
       "23018  Face Mask (Pack of 5) ÃÂ Meeting the need of...          1  \n",
       "8199   The support from customers this week has been ...          1  \n",
       "18271  Why not stay home and be safe?\\r\\r\\n\\r\\r\\nWhil...          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['OriginalTweet'].apply(lambda x: 'amazing' in x) & (train['Sentiment'] == 1)].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jSjbKPCWk87K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Standing in a 40 minute queue for the supermarket and thinking isnÃ\\x82Â\\x92t it amazing to be outside! Highlight of my day... #coronavirus #lockdown'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(train[(train[\"UserName\"] == 30510) & (train[\"ScreenName\"] == 75462)][\"OriginalTweet\"])[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 42351)\t0.2851223738998151\n",
      "  (0, 41557)\t0.12755100190282836\n",
      "  (0, 40938)\t0.30689800182967686\n",
      "  (0, 37226)\t0.29112521399940267\n",
      "  (0, 34982)\t0.2645488975981064\n",
      "  (0, 33093)\t0.33871438496962336\n",
      "  (0, 30402)\t0.30375304682886317\n",
      "  (0, 28944)\t0.354372346368912\n",
      "  (0, 23702)\t0.20662775584607432\n",
      "  (0, 18544)\t0.28759755993549146\n",
      "  (0, 10878)\t0.3008137960548647\n",
      "  (0, 9724)\t0.1748073136069567\n",
      "  (0, 4952)\t0.2579468652236513\n",
      "  (0, 1740)\t0.0891401418809861\n",
      "highlight\n"
     ]
    }
   ],
   "source": [
    "print(tv.transform([a]))\n",
    "print(tv.get_feature_names_out()[tv.transform([a]).argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTv9ST2_U6NA"
   },
   "source": [
    "**Ответ:** # Очень хороший пример - tf-idf выделит как самое важный токен слово highlight, которое чуть менее очевидно, чем good / great / amazing, но тоже подчеркивает позитивность эмоциональной окраски твита"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVEuZm8BHms6"
   },
   "source": [
    "## Задание 4 Обучение первых моделей (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JADkO3sfXdOG"
   },
   "source": [
    "Примените оба векторайзера для получения матриц с признаками текстов.  Выделите целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "DguoiXhCX2oN",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvft_v = cvft.toarray()\n",
    "cvft_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvft_v = tvft.toarray()\n",
    "tvft_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25621    1\n",
       "30135    1\n",
       "28899    1\n",
       "5989     0\n",
       "4367     1\n",
       "        ..\n",
       "20757    0\n",
       "32103    1\n",
       "30403    1\n",
       "21243    0\n",
       "2732     1\n",
       "Name: Sentiment, Length: 23410, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train[\"Sentiment\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FX1KSOfYSx4"
   },
   "source": [
    "Обучите логистическую регрессию на векторах из обоих векторайзеров. Посчитайте долю правильных ответов на обучающих и тестовых данных. Какой векторайзер показал лучший результат? Что можно сказать о моделях?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-Tb3eh8UXJ6v"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4cab3ac9fdca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvft_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1304\u001b[0m             path_func(\n\u001b[1;32m   1305\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             ]\n\u001b[0;32m--> 452\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    453\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    615\u001b[0m                                   **options)\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_multiclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mgrad_pointwise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_reg_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_pointwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr1 = LogisticRegression()\n",
    "lr1.fit(cvft_v, y)\n",
    "\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(tvft_v, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y_wO7rCmv7K"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSOR1i3mjrys"
   },
   "source": [
    "## Задание 5 Стемминг (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6ONBWNPjuq-"
   },
   "source": [
    "Для уменьшения словаря можно использовать стемминг.\n",
    "\n",
    "Модифицируйте написанный токенайзер, добавив в него стемминг с использованием SnowballStemmer. Обучите Count- и Tfidf- векторайзеры. Как изменился размер словаря?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVfA2-iMkQBb"
   },
   "outputs": [],
   "source": [
    "def custom_stem_tokenizer(text):\n",
    "  # -- YOUR CODE HERE --\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QmrjYtqnlPd",
    "outputId": "cd91291d-9676-4611-9fc4-28afaed58963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sampl', 'text', '@sample_text', '#sampletext', 'ad', 'word', 'check', 'stem']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stem_tokenizer('This is sample text!!!! @Sample_text I, \\x92\\x92 https://t.co/sample  #sampletext adding more words to check stemming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAvUTmaplzOS",
    "outputId": "566207fe-183b-4ed6-d333-f86f0cc9ae38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36652\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer # -- YOUR CODE HERE --\n",
    "\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyzs5TaAoHP6"
   },
   "source": [
    "**Ответ** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OkncHI8oRmd"
   },
   "source": [
    "Обучите логистическую регрессию с использованием обоих векторайзеров. Изменилось ли качество? Есть ли смысл применять стемминг?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykZJPphEoZ5W"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCRlrODro0h8"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYWGQNEDqLC-"
   },
   "source": [
    "## Задание  6 Работа с частотами (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hq-tl5mqUSn"
   },
   "source": [
    "Еще один способ уменьшить количество признаков - это использовать параметры min_df и max_df при построении векторайзера  эти параметры помогают ограничить требуемую частоту встречаемости токена в документах.\n",
    "\n",
    "По умолчанию берутся все токены, которые встретились хотя бы один раз.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1SiD4DE3WZ2"
   },
   "source": [
    "Подберите max_df такой, что размер словаря будет 36651 (на 1 меньше, чем было). Почему параметр получился такой большой/маленький?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3YLb8PViExb",
    "outputId": "b6d67654-d232-4e11-a5ca-6f2145053e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36651\n"
     ]
    }
   ],
   "source": [
    "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        max_df=# -- YOUR CODE HERE --\n",
    "                        ).fit(\n",
    "                            # -- YOUR CODE HERE --\n",
    "                            )\n",
    "print(len(cv_df.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyEpkJUkjnuK"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdZYoGZR4UsA"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gRIUaB1u32f"
   },
   "source": [
    "Подберите min_df (используйте дефолтное значение max_df) в CountVectorizer таким образом, чтобы размер словаря был 3700 токенов (при использовании токенайзера со стеммингом), а качество осталось таким же, как и было. Что можно сказать о результатах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSnMJkn9XmsT",
    "outputId": "e0d8eb21-e5d7-46b4-e1d1-4b1ae220e9a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700\n"
     ]
    }
   ],
   "source": [
    "cv_df = CountVectorizer(tokenizer=custom_stem_tokenizer,\n",
    "                        min_df=# -- YOUR CODE HERE --\n",
    "                        ).fit(\n",
    "                            # -- YOUR CODE HERE --\n",
    "                            )\n",
    "print(len(cv_df.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvMDwpdfjm8Y"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fGYpUIZx0fk"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx_h_-inKbBl"
   },
   "source": [
    "В предыдущих заданиях признаки не скалировались. Отскалируйте данные (при словаре размера 3.7 тысяч, векторизованные CountVectorizer), обучите логистическую регрессию, посмотрите качество и выведите `berplot` содержащий по 10 токенов, с наибольшим по модулю положительными/отрицательными весами. Что можно сказать об этих токенах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBATXJX6LG9q"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThcEfzY1LHET"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktJVOdrIHq7B"
   },
   "source": [
    "## Задание 7 Другие признаки (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt3jRCZ2H0Og"
   },
   "source": [
    "Мы были сконцентрированы на работе с текстами твиттов и не использовали другие признаки - имена пользователя, дату и местоположение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52wjewCCo_di"
   },
   "source": [
    "Изучите признаки UserName и ScreenName. полезны ли они? Если полезны, то закодируйте их, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63thouYZptj6"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8_qR-gnpT3a"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ythEcFSkt7y3"
   },
   "source": [
    "Изучите признак TweetAt в обучающей выборке: преобразуйте его к типу datetime и нарисуйте его гистограмму с разделением по цвету на оспнове целевой переменной. Полезен ли он? Если полезен, то закодируйте его, добавьте к матрице с отскалированными признаками, обучите логистическую регрессию, замерьте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lxb_k0JLirNv"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IdLBdpQxM-G"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2JtRPhNP6qx"
   },
   "source": [
    "Поработайте с признаком Location в обучающей выборке. Сколько уникальных значений?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYQZQ1FRNpoe"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k4JwpRTQISa"
   },
   "source": [
    "Постройте гистограмму топ-10 по популярности местоположений (исключая Unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J91YkhegJ0mz"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOsv3lODTfYB"
   },
   "source": [
    "Видно, что многие местоположения включают в себя более точное название места, чем другие (Например, у некоторых стоит London, UK; а у некоторых просто UK или United Kingdom).\n",
    "\n",
    "Создайте новый признак WiderLocation, который содержит самое широкое местоположение (например, из London, UK должно получиться UK). Сколько уникальных категорий теперь? Постройте аналогичную гистограмму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSkow6acOMyD"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgyWrD2eVfff"
   },
   "source": [
    "Закодируйте признак WiderLocation с помощью OHE таким образом, чтобы создались только столбцы для местоположений, которые встречаются более одного раза. Сколько таких значений?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeJBfBWgPvg_"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyMX5kZuimPK"
   },
   "source": [
    "Добавьте этот признак к матрице отскалированных текстовых признаков, обучите логистическую регрессию, замерьте качество. Как оно изменилось? Оказался ли признак полезным?\n",
    "\n",
    "\n",
    "*Подсказка:* используйте параметр `categories` в энкодере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EO1jNPeeim7A"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dHsGlDRYUQt"
   },
   "source": [
    "**Ответ:** # -- YOUR ANSWER HERE --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWn6h4W9eD3S"
   },
   "source": [
    "## Задание 8 Хорошее качество (Бонус 1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HDI0SU6eLgi"
   },
   "source": [
    "Добейтесь accuracy=0.9 на тестовой выборке (можно сменить токенайзер, векторайзер, модель и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3WMbE8edhlW"
   },
   "outputs": [],
   "source": [
    "# -- YOUR CODE HERE --"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
